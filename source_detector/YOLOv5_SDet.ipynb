{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOv5_SDet.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/GretaDanesi18/Olive_Detection_Tracking/blob/main/source_detector/YOLOv5_SDet.ipynb",
      "authorship_tag": "ABX9TyP57sd0WlcGaZm3FPsPGunS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GretaDanesi18/Olive_Detection_Tracking/blob/main/source_detector/YOLOv5_SDet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **SETUP**"
      ],
      "metadata": {
        "id": "GxPdSlsjKIHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Per prima cosa importiamo le librerie necessarie"
      ],
      "metadata": {
        "id": "RvxnaUNGBCfU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ttf8iO2r7-KL"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import os\n",
        "import random \n",
        "import shutil\n",
        "import glob\n",
        "from IPython.display import Image,display\n",
        "from PIL import Image, ImageDraw\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import subprocess\n",
        "from numpy import source\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Controlliamo l'utilizzo del device GPU oppure CPU"
      ],
      "metadata": {
        "id": "wGdE_ROSBIhE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhG6CGpt0mQ5"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    \n",
        "print('Using PyTorch version:', torch.__version__, ' Device:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Successivamente cloniamo la repo contente YOLOv5 e installiamo i requisiti"
      ],
      "metadata": {
        "id": "MSsEQC1mAh7A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJLPGLRQgDJQ"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CREAZIONE DATASET SOURCE DETECTOR**"
      ],
      "metadata": {
        "id": "OopP-gXpKbwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cloniamo la repo contente il dataset iniziale, i frame dei video e il file yaml"
      ],
      "metadata": {
        "id": "LZHeE-4dE5ZC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYkL4OdZ3SE4"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/GretaDanesi18/Olive_Detection_Tracking.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attraverso la libreria os creiamo le directory in cui inserire le labels e le immagini necessarie a creare il dataset per yolov5\n",
        "\n",
        "\n",
        "```\n",
        "/path/to/dataset/...\n",
        "\n",
        "+--images\n",
        "|   +---val\n",
        "         +-----image_1.jpg\n",
        "         +-----image_2.jpg\n",
        "         +-----image_n.jpg\n",
        "|   +---train\n",
        "        +-----image_1.jpg\n",
        "        +-----image_2.jpg\n",
        "        +-----image_n.jpg\n",
        "+--labels\n",
        "|   +---val\n",
        "         +-----label_1.txt\n",
        "         +-----label_2.txt\n",
        "         +-----label_n.txt\n",
        "|   +---train\n",
        "        +-----label_1.txt\n",
        "        +-----label_2.txt\n",
        "        +-----label_n.txt\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "IfJJbvJbE8g_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YIUvadpF85ei"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  if not os.path.exists('/content/yolov5/Olive_Detection_Tracking/images/val'):\n",
        "    os.makedirs('/content/yolov5/Olive_Detection_Tracking/images/val')\n",
        "\n",
        "except OSError:\n",
        "    print('Errore nella creazione della cartella images/val')\n",
        "\n",
        "try:\n",
        "  if not os.path.exists('/content/yolov5/Olive_Detection_Tracking/images/train'):\n",
        "    os.makedirs('/content/yolov5/Olive_Detection_Tracking/images/train')\n",
        "\n",
        "except OSError:\n",
        "    print('Errore nella creazione della cartella images/train')\n",
        "\n",
        "try:\n",
        "  if not os.path.exists('/content/yolov5/Olive_Detection_Tracking/labels/val'):\n",
        "    os.makedirs('/content/yolov5/Olive_Detection_Tracking/labels/val')\n",
        "\n",
        "except OSError:\n",
        "    print('Errore nella creazione della cartella labels/val')\n",
        "\n",
        "try:\n",
        "  if not os.path.exists('/content/yolov5/Olive_Detection_Tracking/labels/train'):\n",
        "    os.makedirs('/content/yolov5/Olive_Detection_Tracking/labels/train')\n",
        "\n",
        "except OSError:\n",
        "    print('Errore nella creazione della cartella labels/train')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attraverso degli array di appoggio dividiamo le labels dalle immagini e settiamo le percentuali con cui fare lo split del dataset"
      ],
      "metadata": {
        "id": "inckMyLbCRBl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2f9vJvmC6kl"
      },
      "outputs": [],
      "source": [
        "\n",
        "#path\n",
        "images_path = '/content/yolov5/Olive_Detection_Tracking/source_detector/dataset_source/images'\n",
        "labels_path = '/content/yolov5/Olive_Detection_Tracking/source_detector/dataset_source/labels'\n",
        "train_image_path = '/content/yolov5/Olive_Detection_Tracking/images/train'\n",
        "val_image_path = '/content/yolov5/Olive_Detection_Tracking/images/val'\n",
        "train_label_path ='/content/yolov5/Olive_Detection_Tracking/labels/train'\n",
        "val_label_path = '/content/yolov5/Olive_Detection_Tracking/labels/val'\n",
        "\n",
        "\n",
        "#percentuale per train, val\n",
        "val_ratio = 0.2\n",
        "train_ratio = 0.8\n",
        "\n",
        "lista_label = sorted(os.listdir(labels_path))\n",
        "lista_image = sorted(os.listdir(images_path))\n",
        "\n",
        "#numero di immagini per train e per val\n",
        "num_train = int(len(lista_image)*train_ratio)\n",
        "num_val = int(len(lista_image)*val_ratio)\n",
        "\n",
        "print(\"Immagini per il training: \", num_train)\n",
        "print(\"Immagini per validation: \", num_val)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con la funzione random separiamo in modo casuale le immagini usate per il training da quelle usate per la validation.\n",
        "\n",
        "Successivamente inseriamo le rispettive labels nella directory per il training oppure per la validation"
      ],
      "metadata": {
        "id": "u-bH0EU0CwtH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vqS9BJb6zBxj"
      },
      "outputs": [],
      "source": [
        "#inserisco image e label in train\n",
        "for i in range(num_train):\n",
        "   file_image = random.choice(lista_image)\n",
        "   file_image_name = file_image.split('.')[0]\n",
        "   file_label =  file_image_name+'.txt'\n",
        "\n",
        "   #sposto i file nella cartella train\n",
        "   source_label = labels_path+'/'+file_label\n",
        "   destination_label = train_label_path+'/'+file_label\n",
        "   shutil.copyfile(source_label,destination_label)\n",
        "\n",
        "   source_image = images_path+'/'+file_image\n",
        "   destination_image = train_image_path+'/'+file_image\n",
        "   shutil.copyfile(source_image,destination_image)\n",
        "\n",
        "   #rimuovo i file dalla lista\n",
        "   lista_image.remove(file_image)\n",
        "   lista_label.remove(file_label)\n",
        "    \n",
        "\n",
        "#inserisco image e label in val  \n",
        "for i in range(num_val):\n",
        "    file_image =random.choice(lista_image)\n",
        "    file_image_name = file_image.split('.')[0]\n",
        "    file_label = file_image_name+'.txt'\n",
        "\n",
        "    #sposto i file nella cartella val\n",
        "    source_label = labels_path+'/'+file_label\n",
        "    destination_label = val_label_path+'/'+file_label\n",
        "    shutil.copyfile(source_label,destination_label)\n",
        "\n",
        "    source_image = images_path+'/'+file_image\n",
        "    destination_image = val_image_path+'/'+file_image\n",
        "    shutil.copyfile(source_image,destination_image)\n",
        "\n",
        "    #rimuovo i file dalla lista\n",
        "    lista_image.remove(file_image)\n",
        "    lista_label.remove(file_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inseriamo file yaml nella directory data"
      ],
      "metadata": {
        "id": "EJ4yKYGmGHeA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN5JAwB-5XwO"
      },
      "outputs": [],
      "source": [
        "source = 'Olive_Detection_Tracking/source_detector/source_dataset.yaml'\n",
        "destination = 'data/source_dataset.yaml'\n",
        "shutil.copy(source,destination)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ADDESTRAMENTO SOURCE DETECTOR**"
      ],
      "metadata": {
        "id": "44G8CBlaKlS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usiamo Weights & Biases per mostrare i risultati.\n",
        "\n",
        "Eventualmente possiamo usare anche tensorboard lanciando il seguente codice dopo aver avviato il training.\n",
        "\n",
        "```\n",
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"runs\"\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "81GdZpOoGK49"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQuyTZA78HiH"
      },
      "outputs": [],
      "source": [
        "#Weights & Biases\n",
        "%pip install -q wandb\n",
        "import wandb\n",
        "wandb.login()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avviamo l'addestramento "
      ],
      "metadata": {
        "id": "AKKpcdCtGSO8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r93_SW6kNYyz"
      },
      "outputs": [],
      "source": [
        "!python train.py --img 1280 --batch 16 --epochs 80 --data source_dataset.yaml --weights yolov5s.pt --cache"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Controlliamo i risultati stampandoli a schermo\n",
        "\n",
        "Modificare i path a seconda di quali risultati si vuole visualizzare"
      ],
      "metadata": {
        "id": "YBdYCYu5GuJs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzjZGcbppWH5"
      },
      "outputs": [],
      "source": [
        "Image.open('runs/train/exp/train_batch0.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALvK-lsGpcmX"
      },
      "outputs": [],
      "source": [
        "Image.open('runs/train/exp/val_batch0_labels.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iNGricnPehg"
      },
      "outputs": [],
      "source": [
        "Image.open('runs/train/exp/val_batch0_pred.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFNHaro4piZf"
      },
      "outputs": [],
      "source": [
        "\n",
        "file_csv=pd.read_csv('runs/train/exp/results.csv')\n",
        "file_csv.head(-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHipLAoJxDhH"
      },
      "outputs": [],
      "source": [
        "Image.open('runs/train/exp/results.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **VALIDATION SOURCE DETECTOR**\n",
        "\n",
        "Dopo aver fatto il training facciamo la validation sul dateset del test"
      ],
      "metadata": {
        "id": "dX8Z5x0AAh1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python val.py --img 1280 --batch 16 --data source_dataset.yaml --weights runs/train/exp/weights/best.pt --task test --save-txt"
      ],
      "metadata": {
        "id": "yjlvK0ORATmW",
        "outputId": "124ab0aa-9d20-4d64-bc69-b8be7f0e5991",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolov5/data/source_dataset.yaml, weights=['runs/train/exp/weights/best.pt'], batch_size=16, imgsz=1280, conf_thres=0.001, iou_thres=0.6, task=test, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=True, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
            "YOLOv5 ðŸš€ v6.1-307-g92e47b8 Python-3.7.13 torch-1.12.0+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 213 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mScanning '/content/yolov5/../yolov5/Olive_Detection_Tracking/test_dataset/labels' images and labels...100 found, 0 missing, 0 empty, 0 corrupt: 100% 100/100 [00:00<00:00, 362.27it/s]\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: /content/yolov5/../yolov5/Olive_Detection_Tracking/test_dataset/labels.cache\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.81s/it]\n",
            "                 all        100       3152      0.639      0.481      0.518      0.163\n",
            "Speed: 3.3ms pre-process, 14.8ms inference, 2.3ms NMS per image at shape (16, 3, 1280, 1280)\n",
            "Results saved to \u001b[1mruns/val/exp\u001b[0m\n",
            "100 labels saved to runs/val/exp/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **INFERENZA SOURCE DETECTOR**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "t5W9qYj2G-Ro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Facciamo il download del weights migliore cosi da salvarlo in locale e poterlo riutilizzare per inferences future\n",
        "\n",
        "Modificare i path in accordo con le proprie directory"
      ],
      "metadata": {
        "id": "r2esa1L6HHvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('runs/train/exp/weights/best.pt')"
      ],
      "metadata": {
        "id": "p24VAnWpiAZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Facciamo l'inferenza, tramite detect.py, sui frame del video1 cosi da ottenere delle labels che poi verrano usate per generare le pseudo labels.\n",
        "\n",
        "L'inferenza viene fatta con una threshold di 0.70.\n",
        " \n",
        "I risultati sono salvati in runs/detect/exp"
      ],
      "metadata": {
        "id": "u-LzyLzxHXJ0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25Nnrwd8c-ih"
      },
      "outputs": [],
      "source": [
        "!python detect.py --source Olive_Detection_Tracking/dataset_video/frame_video/frame_video1 --data data/source_dataset.yaml --img 1280 --weights runs/train/exp/weights/best.pt --save-txt --conf-thres 0.70"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Facciamo l'inferenza anche sui frame del video2 per poi poter confrontare i risultati con i bounding box generati dal target detector"
      ],
      "metadata": {
        "id": "1JYIytmfHTQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --source Olive_Detection_Tracking/dataset_video/frame_video/frame_video2 --data data/source_dataset.yaml --img 1280 --weights runs/train/exp/weights/best.pt --save-txt --conf-thres 0.40"
      ],
      "metadata": {
        "id": "58joIaWdHL6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se vogliamo salvare soltanto le labels creiamo la zip della cartella contenente le labels cosi da poter fare il download e salvarle in locale."
      ],
      "metadata": {
        "id": "Ybm4HpRkIWGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r source_detection_labels.zip runs/detect/exp/labels"
      ],
      "metadata": {
        "id": "5HvS-pixupJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"source_detection_labels.zip\")\n"
      ],
      "metadata": {
        "id": "htIUouvXvH_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Per salvare sia le labels che le immagini facciamo il download di tutta la cartella in cui sono salvati i risultati runs/detect/exp "
      ],
      "metadata": {
        "id": "3QUNo2bbikhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r source_detection_results.zip runs/detect/exp"
      ],
      "metadata": {
        "id": "Xulrr4Ktij9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"source_detection_results.zip\")"
      ],
      "metadata": {
        "id": "cYOab5n-i_cG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Per salvare tutti i risultati"
      ],
      "metadata": {
        "id": "YtAsKoCNhi33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r source_results.zip runs"
      ],
      "metadata": {
        "id": "S0YUM0D7hjWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"source_results.zip\")"
      ],
      "metadata": {
        "id": "TjzS19Bphz3O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}